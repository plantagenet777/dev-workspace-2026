## ML Report: Pump Monitor Random Forest

This document summarizes the current ML setup and validation results for the
predictive maintenance engine.

### 1. Dataset

- **Source:** synthetic data generated by `train_and_save.py`.
- **Domain alignment:** the synthetic generator uses
  `Config.HEALTHY_MEANS`, `WARNING_MEANS`, `CRITICAL_MEANS` and vibration
  thresholds from `config/config.py`, so the three classes are consistent with:
  - ISO 10816-3 vibration zones (B, C, D);
  - operating instruction thresholds for slurry pumps (pressure, current, temp).
- **Size:** by default `samples=5000`.
- **Class balance (by design):**
  - Healthy (0): 80%
  - Warning (1): 10%
  - Critical (2): 10%

The engine uses 8 features:

- `vib_rms`, `vib_crest`, `vib_kurtosis`
- `current`, `pressure`
- `cavitation_index`
- `temp`, `temp_delta`

These are exactly the `Config.FEATURE_NAMES` used in both training and
inference.

### 2. Model

The current model is a scikit-learn `RandomForestClassifier`:

- `n_estimators=150`
- `max_depth=10`
- `class_weight="balanced"`
- `random_state=42`

Input features are standardized with `StandardScaler`. Artifacts are stored as:

- model: `models/pump_rf_<MODEL_VERSION>.joblib`
- scaler: `models/scaler_<MODEL_VERSION>.joblib`

### 3. Evaluation protocol

`train_and_save.py` uses the following protocol:

- generate synthetic dataset (seed = 42);
- split into **80% train / 20% validation**, stratified by class;
- fit scaler and model on the train split only;
- evaluate on the validation split with:
  - balanced accuracy;
  - per-class precision/recall/F1;
  - confusion matrix;
  - feature importance.

The script writes a plain-text report to:

```text
models/ml_report.txt
```

and prints the same content to stdout. To regenerate:

```bash
make train
# or:
PYTHONPATH=. ./venv/bin/python train_and_save.py
```

### 4. Current validation metrics (synthetic)

Last recorded run (seed 42, 5000 samples) produced:

- **Balanced accuracy:** 1.0000

```text
Classification report (validation set):
              precision    recall  f1-score   support

     Healthy     1.0000    1.0000    1.0000       800
     Warning     1.0000    1.0000    1.0000       100
    Critical     1.0000    1.0000    1.0000       100

    accuracy                         1.0000      1000
   macro avg     1.0000    1.0000    1.0000      1000
weighted avg     1.0000    1.0000    1.0000      1000
```

Confusion matrix (rows = true label, columns = predicted):

```text
  Healthy  Warning  Critical
      800        0         0   <- Healthy
        0      100         0   <- Warning
        0        0       100   <- Critical
```

This perfect score is expected on synthetic Gaussian data with clearly separated
class means. It does **not** guarantee the same quality on real plant data, but
it is a sanity check that:

- the labels and features are consistent;
- the model can distinguish the three zones given the current thresholds.

### 5. Feature importance

Feature importances from the same run:

```text
  vib_kurtosis: 0.1926
  vib_rms: 0.1902
  temp: 0.1817
  pressure: 0.1685
  cavitation_index: 0.1517
  vib_crest: 0.0757
  current: 0.0328
  temp_delta: 0.0068
```

Interpretation:

- vibration-related features (`vib_kurtosis`, `vib_rms`, `vib_crest`) and
  process variables (`temp`, `pressure`, `cavitation_index`) dominate;
- `current` and especially `temp_delta` play a secondary role in the current
  synthetic generator.

This is consistent with the rule-based logic: vibration, temperature and
pressure are the primary indicators of transition from Healthy → Warning →
Critical.

### 6. Business impact (illustrative)

The metrics above translate into the following potential impact for a single
slurry pump on a critical circuit (illustrative numbers for explanation):

- assume 2–3 unplanned failures per year, each causing 4–8 hours of downtime;
- typical cost of 1 hour of lost production on a grinding/flotation circuit can
  easily reach **\$5k–\$20k** (ore type and plant size dependent);
- if the PdM engine allows maintenance to detect degradation and cavitation
  early enough to prevent even **1–2** such events per year, the avoided loss
  is on the order of **\$40k–\$200k/year per pump**, not counting reduced
  mechanical damage (impeller, bearings) and safer operation.

These are back-of-the-envelope estimates; actual impact depends on plant
economics, adherence to alerts and how aggressively shutdown scenarios are
enabled. The main goal of the model and ruleset is to:

- surface clear, explainable alerts (what happened and why);
- shift decisions from purely reactive (trip → investigation) to
  data-driven planned interventions (WARNING zone with context).

### 7. Limitations and next steps

- **Synthetic only.** Current metrics are computed on synthetic data aligned
  with `simulate_failure.py` and ISO thresholds. Real plant data may have
  different noise, drift and correlations.
- **No time-series CV.** The protocol uses a simple random split rather than a
  temporal split; for real time-series data a walk-forward validation would be
  more appropriate.
- **Domain shift.** If `Config` thresholds or `HEALTHY_MEANS` / `WARNING_MEANS`
  / `CRITICAL_MEANS` change, the generator and the trained model must be
  re-aligned by rerunning `make train`.

Recommended future work for a production deployment:

- collect and label real plant telemetry (at least a few hundred events);
- re-train and re-evaluate the model on real data with time-aware splits;
- add monitoring of score distributions and drift (e.g. via periodic analysis
  of `telemetry_history.csv`).
